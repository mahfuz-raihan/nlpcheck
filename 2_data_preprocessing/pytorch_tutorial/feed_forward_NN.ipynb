{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building Simple FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/media/mahfuz/Media/datasets/MNIST_dataset/mnist_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "X = df.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8x5</th>\n",
       "      <th>8x6</th>\n",
       "      <th>8x7</th>\n",
       "      <th>8x8</th>\n",
       "      <th>8x9</th>\n",
       "      <th>8x10</th>\n",
       "      <th>8x11</th>\n",
       "      <th>8x12</th>\n",
       "      <th>8x13</th>\n",
       "      <th>8x14</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56526</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>251</td>\n",
       "      <td>253</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>233</td>\n",
       "      <td>171</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43593</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>167</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13377</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31487</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12236</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51339</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 584 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       8x5  8x6  8x7  8x8  8x9  8x10  8x11  8x12  8x13  8x14  ...  28x19  \\\n",
       "56526    0    0    0    0   79   251   253   127     0     0  ...      0   \n",
       "53497    0    0    0    0    0     0     0     0    16    75  ...      0   \n",
       "54126    0    0    0    0    0    18   233   171    20     3  ...      0   \n",
       "29973    0    0    0    0    0     0     0     0     0     0  ...      0   \n",
       "43593    0    0    0    0    0     0     0     7   167   254  ...      0   \n",
       "13377    0    0    0    0    0     0     0     0     0     0  ...      0   \n",
       "31487    0    0    0    0    0     0     0     0     0     0  ...      0   \n",
       "9992     0    0    0    0    0     0     0     0     0     0  ...      0   \n",
       "12236    0    0    0    0    0     0     0     0     0     0  ...      0   \n",
       "51339    0    0    0    0    0     0     0     0    32   234  ...      0   \n",
       "\n",
       "       28x20  28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "56526      0      0      0      0      0      0      0      0      0  \n",
       "53497      0      0      0      0      0      0      0      0      0  \n",
       "54126      0      0      0      0      0      0      0      0      0  \n",
       "29973      0      0      0      0      0      0      0      0      0  \n",
       "43593      0      0      0      0      0      0      0      0      0  \n",
       "13377      0      0      0      0      0      0      0      0      0  \n",
       "31487      0      0      0      0      0      0      0      0      0  \n",
       "9992       0      0      0      0      0      0      0      0      0  \n",
       "12236      0      0      0      0      0      0      0      0      0  \n",
       "51339      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[10 rows x 584 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(10).iloc[:, 200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize=(12,5))\n",
    "axes = axes.flatten()\n",
    "idx = np.random.randint(0,6000, size=10)\n",
    "for i in range(10):\n",
    "    axes[i].imshow(X.iloc[idx[i],:].values.reshape(28,28), cmap='gray')\n",
    "    axes[i].axis('off') # hide the exes ticks \n",
    "    axes[i].set_title(str(int(y[idx[i]])), color='black', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trian and text val dataset splitting \n",
    "x_t, x_test, y_t, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_t, y_t, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizeing the dataset\n",
    "\n",
    "normalizer = Normalizer()\n",
    "x_train = normalizer.fit_transform(x_train)\n",
    "x_val = normalizer.transform(x_val)\n",
    "x_test = normalizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(range(1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader\n",
    "1. Basic idea behind the ```Dataset``` and ```DataLoader``` class is to be decoupled from our model training code for beter readability and modularity. \n",
    "2. PyTorch provides two data primitive: ```torch.utils.data.DataLoader``` and ```torch.utils.data.Datasets``` that allow you to use pre-loader datasets as well as your own data. \n",
    "3. ```Dataset``` class stores the samples and their corresponding labels, and ```DataLoader``` class wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "\n",
    "## Data Class\n",
    "A custom Dataset class must implement thre functions: ```__init__```, ```__len__``` and ```__getitem__```.\n",
    "1. The ```__init__``` function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both tranforms \n",
    "2. The ```__len__`` funcition returns the number of samples in our dataset.\n",
    "3. The ```__getitem__``` function loads and returns sample from the dataset at the given index idx. Based on the index, it identifies the sample and label and return it as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number': tensor([4, 9]), 'square': tensor([16, 81])}\n",
      "{'number': tensor([3, 7]), 'square': tensor([ 9, 49])}\n",
      "{'number': tensor([5, 2]), 'square': tensor([25,  4])}\n",
      "{'number': tensor([1, 6]), 'square': tensor([ 1, 36])}\n",
      "{'number': tensor([0, 8]), 'square': tensor([ 0, 64])}\n"
     ]
    }
   ],
   "source": [
    "# Example code to understand dataset and DataLoader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Step 1: Define the custom Dataset\n",
    "class SquareDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'number': idx, 'square': idx ** 2}\n",
    "        return sample\n",
    "\n",
    "# Step 2: Create an instance of the dataset\n",
    "dataset = SquareDataset(n=10)\n",
    "\n",
    "# Step 3: Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Step 4: Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a custom dataset. \n",
    "class customer_dataset(Dataset):\n",
    "    def __init__(self, features, label):\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.features[idx]\n",
    "        label = self.label.values[idx]\n",
    "        sample_tensor = torch.tensor(sample, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return sample_tensor, label_tensor\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customer_dataset(x_train, y_train)\n",
    "val_dataset = customer_dataset(x_val, y_val)\n",
    "test_dataset = customer_dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader class\n",
    "The Dataset retrives our dataset's features and label one sample at a time. While training a model, we typically want to pass smaple in 'minibatches', reshuffle the data at every epoch to reduce model overfitting and use python's multiprocessing to speed up data retrival.\n",
    "\n",
    "```DataLoader is an iterable that abstracts this compliexity for  us in an easy API```\n",
    "\n",
    "When we load the dataset into DataLoader and we can iterate through the dataset as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1051, 0.0843, 0.0062],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0839, 0.1208, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0808, 0.0808, 0.0808],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0936, 0.0936, 0.0451],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0828, 0.0828, 0.0828],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([0, 8, 8, 9, 5, 3, 7, 3, 2, 4, 4, 0, 9, 6, 8, 4, 8, 1, 8, 8, 0, 3, 1, 1,\n",
      "        2, 6, 1, 6, 3, 7, 1, 2, 6, 4, 8, 7, 6, 8, 6, 0, 9, 6, 5, 2, 3, 1, 9, 3,\n",
      "        2, 4, 2, 6, 0, 0, 1, 9, 8, 9, 8, 0, 2, 3, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "data, label = next(iter(train_dataloader))\n",
    "print(data[:, 278:300])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```torch.nn.module``` and ```torch.nn.Parameter```\n",
    "\n",
    "Except for ```Parameter```, the classes we will be discussinga are all subclasses of ```torch.nn.Module```. \n",
    "\n",
    "```torch.nn.module``` is the Pytorch base class which is meant to encapsulate behaviors specific to ```PyTroch Models``` and their ```Component``` like activation functions etc. \n",
    "\n",
    "One of the important behavior of ```torch.nn.Moudle``` is registering(Intializing) parameters for the layers as instance of ```torch.nn.Parameter``` class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super.__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using nn.Sequential\n",
    "1. This approach represent Model as a sequence of Operations\n",
    "2. It the concise way to define a model, but offers less flexibility for model that require complex data flows or custom.\n",
    "4. ```nn.Sequential``` expect modules as it's argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Batch Normalization and Dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p = 0.2)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout_2 = nn.Dropout(p = 0.2)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout_1(self.relu1(self.batch_norm1(self.fc1(x))))\n",
    "        x = self.dropout_2(self.relu2(self.batch_norm2(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "best_loss = 1e9\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(5)\n",
    "a.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: train_loss = 0.2268229 | val_loss = 0.0017028 \n",
      "11: train_loss = 0.0264401 | val_loss = 0.0011525 \n",
      "Early Stopping !!!\n"
     ]
    }
   ],
   "source": [
    "# Training of a model\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  \n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_count = 0\n",
    "    train_pred = 0\n",
    "    for data,label in train_dataloader:\n",
    "        data,label = data.to(device),label.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_fn(pred,label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_pred += (pred.argmax(1) == label).sum().type(torch.float).item()\n",
    "        train_count += 1\n",
    "\n",
    "    train_loss = train_loss / train_count\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_count = 0\n",
    "        val_pred = 0\n",
    "        for data,label in val_dataloader:\n",
    "            data,label = data.to(device),label.to(device)\n",
    "            pred = model(data)\n",
    "            loss = loss_fn(pred,label)\n",
    "            val_pred += (pred.argmax(1) == label).sum().type(torch.float).item()\n",
    "            val_count += len(label)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss = val_loss / val_count\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            count = 0\n",
    "            best_loss = val_loss\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"Model checkpoint: {epoch+1}\")\n",
    "        else:\n",
    "            count += 1\n",
    "        if count == patience:\n",
    "            print(\"Early Stopping !!!\")\n",
    "            break\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "            print(f\"{epoch+1}: train_loss = {train_loss:.7f} | val_loss = {val_loss:.7f} \" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0011, Test Accuracy: 98.12%\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model checkpoint\n",
    "checkpoint_path = '/home/mahfuz/Desktop/nlpcheck/2_data_preprocessing/pytorch_tutorial/Model checkpoint: 7'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Assuming model and optimizer are defined elsewhere in your code\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load your test dataset\n",
    "# Assuming test_dataloader is defined elsewhere in your code and loaded with test data\n",
    "test_dataloader = test_dataloader\n",
    "\n",
    "# Initialize variables to monitor test performance\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "# No gradient updates needed for testing\n",
    "with torch.no_grad():\n",
    "    for data, label in test_dataloader:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_fn(pred, label)\n",
    "        test_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == label).sum().item()\n",
    "\n",
    "# Calculate average loss and accuracy over the test set\n",
    "test_loss /= len(test_dataloader.dataset)\n",
    "test_accuracy = 100. * correct / len(test_dataloader.dataset)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = checkpoint['epoch']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
